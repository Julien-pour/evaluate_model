{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.sum([1,2,3])\n",
    "type(float(a/a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import*\n",
    "def f(n: int) -> bool:\n",
    "    \"\"\"Determine if a given integer 'n' is a power of two.\"\"\"\n",
    "    return n > 0 and (n & (n - 1)) == 0\n",
    "def g():\n",
    "    return 16\n",
    "assert f(g())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=16\n",
    "n & (n - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['elm', 'elm_NLP', 'imgep_random', 'imgep_smart', 'rd_gen']\n",
    "path=\"/home/flowers/project/evaluate_model/save_results/elmopen_llama_3b_v2_e2_seed_21.json\"\n",
    "pass_k=[\n",
    "    {\n",
    "        \"pass_1\": 159.2,\n",
    "        \"pass_2\": 235.97777777777776,\n",
    "        \"pass_3\": 283.975,\n",
    "        \"pass_4\": 317.9666666666667,\n",
    "        \"pass_5\": 343.82142857142856,\n",
    "        \"pass_6\": 364.4238095238095,\n",
    "        \"pass_7\": 381.4166666666667,\n",
    "        \"pass_8\": 395.79999999999995,\n",
    "        \"pass_9\": 408.20000000000005,\n",
    "        \"pass_10\": 419.0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "path=\"/home/flowers/project/evaluate_model/save_feat/.WizardCoder-1B-V1.0_feat.pkl.Dz0o9L\"\n",
    "with open(path, 'rb') as f:\n",
    "    feat_dict = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rd_gen\n",
    "3\n",
    "elm\n",
    "3\n",
    "elm_NLP\n",
    "1 3\n",
    "imgep_random\n",
    "1 3\n",
    "imgep_smart\n",
    "3\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "import os\n",
    "def just_remove_example_in_docstring(source_code: str) -> str:\n",
    "    puzzle_formated= source_code\n",
    "\n",
    "    # Parse the source code into an AST\n",
    "    tree = ast.parse(source_code)\n",
    "\n",
    "    # Extract the docstring from function f and remove it\n",
    "    f_docstring = None\n",
    "    for item in tree.body:\n",
    "        if isinstance(item, ast.FunctionDef) and item.name == 'f':\n",
    "            if ast.get_docstring(item):\n",
    "                f_docstring = ast.get_docstring(item)\n",
    "                if (f_docstring != None):\n",
    "                    delimiters =\"example\",\"Example\",\"For example\",\"Example:\"\n",
    "                    regex_pattern = '|'.join(map(re.escape, delimiters))\n",
    "                    f_docstring_split = re.split(regex_pattern, f_docstring)[0]\n",
    "                    item.body[0].value.s = f_docstring_split\n",
    "    if (f_docstring != None):\n",
    "        # Convert the modified AST back to source code\n",
    "        puzzle_formated=ast.unparse(tree)\n",
    "    puzzle_formated=puzzle_formated.replace('\"\"\"\"\"\"',\"\")\n",
    "    puzzle_formated = os.linesep.join([s for s in puzzle_formated.splitlines() if s.strip()]) # remove empty line\n",
    "\n",
    "    return puzzle_formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path=\"/home/flowers/project/evaluate_model/save_feat/P3_trainWizardCoder-1B-V1.0.json\"\n",
    "with open(path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "len(data),len(data[0][\"emb_features\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset,concatenate_datasets\n",
    "from utils_test import remove_example_line,prompt_solve_puzzle\n",
    "\n",
    "path= \"/home/flowers/project/evaluate_model/run_saved/maps_2_imgep_smart.json\"\n",
    "print(path)\n",
    "with open(path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "list_prg=[puz[\"program_str\"] for puz in data]\n",
    "dataset_r = load_dataset(\"json\", data_files=path, split=\"train\")\n",
    "output_texts=[]\n",
    "for i in range(len(dataset_r['program_str'])):\n",
    "    try:\n",
    "        puzzle= just_remove_example_in_docstring(dataset_r[\"program_str\"][i])\n",
    "        prompt_f=puzzle.split(\"def g(\")[0]\n",
    "        prompt_g= \"def g(\" + puzzle.split(\"def g(\")[1]\n",
    "        full_prompt = prompt_solve_puzzle.format(pb=prompt_f,g_firstline=prompt_g)\n",
    "        output_texts.append(full_prompt)\n",
    "    except:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_r[\"program_str\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_r[\"program_str\"][i])\n",
    "print(\"===============\")\n",
    "remove_example_line(dataset_r[\"program_str\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset,concatenate_datasets\n",
    "from utils_test import remove_example_line\n",
    "\n",
    "path= \"run_saved/maps_1_imgep_random.json\"\n",
    "print(path)\n",
    "with open(path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "list_prg=[puz[\"program_str\"] for puz in data]\n",
    "dataset_r = load_dataset(\"json\", data_files=path, split=\"train\")\n",
    "list_aa=[]\n",
    "for i in range(len(dataset_r['program_str'])):\n",
    "    \n",
    "    puzzle= remove_example_line(dataset_r[\"program_str\"][i])\n",
    "    list_aa.append(puzzle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puz=\"from typing import*\\nfrom typing import List\\n\\ndef f(nums: List[int]) -> int:\\n    \\\"\\\"\\\"Find the sum of the squares of the three largest numbers in the given list\\\"\\\"\\\"\\n    sorted_nums = sorted(nums, reverse=True)\\n    return sum([num**2 for num in sorted_nums[:3]])\\n\\ndef g():\\n    return [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\\n\\nassert f(g()) == 245\\n\"\n",
    "print(puz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_test import pass_at_k,prompt_solve_puzzle\n",
    "model_id = \"openlm-research/open_llama_3b_v2\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_id,local_files_only=True)\n",
    "\n",
    "def formatting_prompts_func(example,prompt_solve_puzzle=prompt_solve_puzzle):\n",
    "    output_texts = []\n",
    "    # print(len(example['program_str']))\n",
    "    for i in range(len(example['program_str'])):\n",
    "        if True:\n",
    "            puzzle= remove_example_line(example['program_str'][i])\n",
    "        else:\n",
    "            puzzle= example['program_str'][i]\n",
    "\n",
    "        prompt_f=puzzle.split(\"def g(\")[0]\n",
    "        prompt_g= \"def g(\" + puzzle.split(\"def g(\")[1]\n",
    "        full_prompt = prompt_solve_puzzle.format(pb=prompt_f,g_firstline=prompt_g)\n",
    "        output_texts.append(full_prompt)\n",
    "    return output_texts\n",
    "\n",
    "def _prepare_non_packed_dataloader(\n",
    "    tokenizer, dataset, dataset_text_field, max_seq_len, formatting_func=None\n",
    "):\n",
    "    use_formatting_func = formatting_func is not None and dataset_text_field is None\n",
    "\n",
    "    # Inspired from: https://huggingface.co/learn/nlp-course/chapter7/6?fw=pt\n",
    "    def tokenize(element):\n",
    "        outputs = tokenizer(\n",
    "            formatting_func(element),\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            max_length=max_seq_len,\n",
    "            return_overflowing_tokens=False,\n",
    "            return_length=False,\n",
    "        )\n",
    "\n",
    "        if use_formatting_func:\n",
    "            if not isinstance(formatting_func(element), list):\n",
    "                raise ValueError(\n",
    "                    \"The `formatting_func` should return a list of processed strings since it can lead to silent bugs.\"\n",
    "                )\n",
    "        return {\"input_ids\": outputs[\"input_ids\"], \"attention_mask\": outputs[\"attention_mask\"]}\n",
    "\n",
    "    tokenized_dataset = dataset.map(\n",
    "        tokenize,\n",
    "        batched=True,\n",
    "        remove_columns=dataset.column_names,\n",
    "        num_proc=2,\n",
    "        batch_size=8,\n",
    "    )\n",
    "\n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_prepare_non_packed_dataloader("
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample puzzles 2 label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "path = \"/home/flowers/project/evaluate_model/run_saved/maps_1_imgep_smart.json\"\n",
    "with open(path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "list_prg=[puz[\"program_str\"] for puz in data]\n",
    "for puzz in data:\n",
    "    \n",
    "    emb=np.array(puzz[\"emb\"],dtype=int).tolist()\n",
    "    puzz[\"emb\"]=emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "rng = np.random.default_rng(seed=42)\n",
    "list_puzzle_2_label=[]\n",
    "list_label=np.array([0. for _ in range((10))])\n",
    "\n",
    "path = \"/home/flowers/project/evaluate_model/run_saved/maps_1_imgep_smart.json\"\n",
    "with open(path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "list_prg=[puz[\"program_str\"] for puz in data]\n",
    "list_emb=[puz[\"emb\"] for puz in data]\n",
    "idx_uniform=rng.choice(len(data), 30, replace=False)\n",
    "print(len(data))\n",
    "for idx_unif in idx_uniform:\n",
    "    list_puzzle_2_label.append(copy.deepcopy(data[idx_unif]))\n",
    "    list_label-=np.array(data[idx_unif][\"emb\"])\n",
    "    del data[idx_unif]\n",
    "print(len(data))\n",
    "\n",
    "for idx_del,puzz in enumerate(data):\n",
    "    \n",
    "    emb=np.array(puzz[\"emb\"],dtype=int).tolist()\n",
    "    puzz[\"emb\"]=emb\n",
    "    if np.sum(emb)==10:\n",
    "        del data[idx_del]\n",
    "print(len(data))\n",
    "\n",
    "idx_shuffle=np.array([i for i in range(len(data))])\n",
    "rng.shuffle(idx_shuffle)\n",
    "while len(list_puzzle_2_label)<60:\n",
    "    for choosen_idx in idx_shuffle:\n",
    "        if len(list_puzzle_2_label)>=60:\n",
    "            break\n",
    "        idx2aim = np.argmax(list_label)\n",
    "        puzzle=data[choosen_idx]\n",
    "        emb=puzzle[\"emb\"]\n",
    "        if emb[idx2aim]==1:\n",
    "            list_puzzle_2_label.append(puzzle)\n",
    "            list_label-=np.array(emb)\n",
    "list_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([i for i in range(10)],-list_label)\n",
    "plt.xlabel(\"skill idx\")\n",
    "plt.ylabel(\"number of puzzle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_2=[ puzz[\"emb\"] for puzz in list_puzzle_2_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist((np.sum(emb_2,axis=1)),bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_puzzles=\"/home/flowers/project/evaluate_model/subset2label.json\"\n",
    "list_results=[]\n",
    "\n",
    "    \n",
    "with open(path_puzzles) as f:\n",
    "        archive=json.load(f)\n",
    "list_emb =[item[\"emb\"] for item in archive]\n",
    "count=0\n",
    "print((np.sum(list_emb,axis=1)==10).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sum(list_emb,axis=1),bins=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_puzzle_2_label\n",
    "path = \"/home/flowers/project/evaluate_model/subset2label.json\"\n",
    "with open(path, 'w') as f:\n",
    "    json.dump(list_puzzle_2_label,f,indent=4)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label puzzles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_puzzle_2_label\n",
    "path = \"/home/flowers/project/evaluate_model/subset2label.json\"\n",
    "with open(path, 'r') as f:\n",
    "    data2label = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1155    1472   \n",
    "1406    1268  \n",
    "1117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(data2label)):\n",
    "    if not (\"GT_emb\" in data2label[idx].keys()):\n",
    "        print(data2label[idx][\"program_str\"])\n",
    "        \n",
    "        data2label[idx][\"GT_emb\"]\n",
    "\n",
    "    data2label[\"program_str\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "truth_labels = [\n",
    " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
    " [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
    " [0, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n",
    "]\n",
    "\n",
    "detected_labels = [\n",
    " [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
    " [0, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
    " [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
    " [0, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# number of labels\n",
    "n_labels = len(truth_labels[0])\n",
    "\n",
    "# initialize matrix\n",
    "matrix = np.zeros((n_labels, n_labels))\n",
    "\n",
    "# count for each ground truth label\n",
    "label_counts = np.zeros(n_labels)\n",
    "\n",
    "\n",
    "\n",
    "for truth, detected in zip(truth_labels, detected_labels):\n",
    "    for i in range(n_labels):\n",
    "        if truth[i] == 1:\n",
    "            label_counts[i] += 1\n",
    "            for j in range(n_labels):\n",
    "                if detected[j] == 1:\n",
    "                    matrix[i][j] += 1\n",
    "\n",
    "# Normalize\n",
    "for i in range(n_labels):\n",
    "    if label_counts[i] != 0:\n",
    "        matrix[i] = matrix[i] / label_counts[i]\n",
    "\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_rd=\"/home/flowers/project/evaluate_model/run_saved/maps_1_rd_gen.json\"\n",
    "path_elm=\"/home/flowers/project/evaluate_model/run_saved/maps_1_elm.json\"\n",
    "path_elm_nl=\"/home/flowers/project/evaluate_model/run_saved/maps_1_elm_NLP.json\"\n",
    "path_imrd = \"/home/flowers/project/evaluate_model/run_saved/maps_1_imgep_random.json\"\n",
    "path_imgep = \"/home/flowers/project/evaluate_model/run_saved/maps_1_imgep_smart.json\"\n",
    "\n",
    "list_path = [path_rd,path_elm,path_elm_nl,path_imrd,path_imgep]\n",
    "name=[\"rd\",\"elm\",\"elm_nl\",\"imrd\",\"imgep\"]\n",
    "list_res=[]\n",
    "for i,path in enumerate(list_path):\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    list_prg=[puz[\"program_str\"] for puz in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def generate_vectors(n):\n",
    "    return [list(p) for p in itertools.product([0, 1], repeat=n)]\n",
    "\n",
    "vectors = generate_vectors(10)\n",
    "for vector in vectors:\n",
    "    print(vector)\n",
    "dic={str(vector): [] for vector in vectors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openelm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
